{
  "metadata": {
    "kernelspec": {
      "name": "glue_pyspark",
      "display_name": "Glue PySpark",
      "language": "python"
    },
    "language_info": {
      "name": "Python_Glue_Session",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "pygments_lexer": "python3",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AWS Glue Studio Notebook\n",
        "##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n"
      ],
      "metadata": {
        "editable": true,
        "trusted": true,
        "id": "r6XvwLP0lkB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optional: Run this cell to see available notebook commands (\"magics\").\n"
      ],
      "metadata": {
        "editable": true,
        "trusted": true,
        "id": "2KNYhYdklkB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%help"
      ],
      "metadata": {
        "trusted": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8KhJKdylkB6",
        "outputId": "7b0cd5f3-b95e-48e6-e0c6-2790f0545a26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%help` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Run this cell to set up and start your interactive session.\n"
      ],
      "metadata": {
        "editable": true,
        "trusted": true,
        "id": "LxMnQL46lkB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%idle_timeout 2880\n",
        "%glue_version 4.0\n",
        "%worker_type G.1X\n",
        "%number_of_workers 5\n",
        "\n",
        "import sys\n",
        "from awsglue.transforms import *\n",
        "from awsglue.utils import getResolvedOptions\n",
        "from pyspark.context import SparkContext\n",
        "from awsglue.context import GlueContext\n",
        "from awsglue.job import Job\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "glueContext = GlueContext(sc)\n",
        "spark = glueContext.spark_session\n",
        "job = Job(glueContext)"
      ],
      "metadata": {
        "trusted": true,
        "editable": true,
        "id": "SEY2VYxClkB7",
        "outputId": "edd91ca4-9e0a-4b0d-ceb9-fb3375b8df35"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.2 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 3e9c8a7e-66d3-4590-ae32-25a0b344e8bb\nApplying the following default arguments:\n--glue_kernel_version 1.0.2\n--enable-glue-datacatalog true\nWaiting for session 3e9c8a7e-66d3-4590-ae32-25a0b344e8bb to get into ready status...\nSession 3e9c8a7e-66d3-4590-ae32-25a0b344e8bb has been created.\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n"
      ],
      "metadata": {
        "editable": true,
        "trusted": true,
        "id": "Ity5eEjBlkB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dyf = glueContext.create_dynamic_frame.from_catalog(database='grocery-db', table_name='input')\n",
        "dyf.printSchema()"
      ],
      "metadata": {
        "trusted": true,
        "editable": true,
        "id": "JEFkJsx1lkB8",
        "outputId": "05d11699-488c-4cc9-840f-171e6649829a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "root\n|-- idx: long\n|-- transaction_id: string\n|-- timestamp: string\n|-- product_id: string\n|-- category: string\n|-- customer_type: string\n|-- unit_price: double\n|-- quantity: long\n|-- total: double\n|-- payment_type: string\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count The Number of Rows in a Dynamic Dataframe\n",
        "dyf.count()"
      ],
      "metadata": {
        "id": "0R2ASj32mMCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting certain fields from a Dynamic DataFrame\n",
        "dyfSelect = dyf.select_fields([\"timestamp\", \"category\"])\n",
        "\n",
        "# Show top 10\n",
        "dyfSelect.show(10)"
      ],
      "metadata": {
        "id": "eElsOXF_mXy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop Fields of Dynamic Frame\n",
        "dyfDrop = dyf.drop_fields([\"transaction_id\",\"payment_type\"])\n",
        "\n",
        "# Show Top 10 rows of dyfCustomerDropFields Dynamic Frame\n",
        "dyfDrop.show(10)\n"
      ],
      "metadata": {
        "id": "bxHP3WYlmh0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping array for column rename fullname -> name\n",
        "mapping=[(\"idx\", \"long\", \"index\", \"long\")]\n",
        "\n",
        "# Apply the mapping to rename fullname -> name\n",
        "dfyMapping = ApplyMapping.apply(\n",
        "                                frame = dyf,\n",
        "                                mappings = mapping,\n",
        "                                transformation_ctx = \"applymapping1\"\n",
        "                                )\n",
        "\n",
        "# show the new dynamic frame with name column\n",
        "dfyMapping.show(10)"
      ],
      "metadata": {
        "id": "hsbSRXupmxvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter dynamicFrameCustomers for customers who have the last name Adams\n",
        "dyfFilter=  Filter.apply(frame = dyf,\n",
        "                                        f = lambda x: x[\"category\"] in \"fruit\"\n",
        "                                    )\n",
        "\n",
        "# Show the top 10 customers  from the filtered Dynamic frame\n",
        "dyfFilter.show(10)"
      ],
      "metadata": {
        "id": "QEwdQ_HFnUxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example: Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n"
      ],
      "metadata": {
        "editable": true,
        "trusted": true,
        "id": "qkzVezqWlkB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparkDf = dyf.toDF()\n",
        "sparkDf.show()"
      ],
      "metadata": {
        "trusted": true,
        "editable": true,
        "id": "arZZVcEklkB_",
        "outputId": "3afb7e2c-a502-4f10-f01a-71038ccf9621"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "+---+--------------------+-------------------+--------------------+--------+-------------+----------+--------+-----+------------+\n|idx|      transaction_id|          timestamp|          product_id|category|customer_type|unit_price|quantity|total|payment_type|\n+---+--------------------+-------------------+--------------------+--------+-------------+----------+--------+-----+------------+\n|  0|a1c82654-c52c-45b...|2022-03-02 09:51:38|3bc6c1ea-0198-46d...|   fruit|         gold|      3.99|       2| 7.98|    e-wallet|\n|  1|931ad550-09e8-4da...|2022-03-06 10:33:59|ad81b46c-bf38-41c...|   fruit|     standard|      3.99|       1| 3.99|    e-wallet|\n|  2|ae133534-6f61-4cd...|2022-03-04 17:20:21|7c55cbd4-f306-4c0...|   fruit|      premium|      0.19|       2| 0.38|    e-wallet|\n|  3|157cebd9-aaf0-475...|2022-03-02 17:23:58|80da8348-1707-403...|   fruit|         gold|      0.19|       4| 0.76|    e-wallet|\n|  4|a81a6cd3-5e0c-44a...|2022-03-05 14:32:43|7f5e86e6-f06f-45f...|   fruit|        basic|      4.49|       2| 8.98|  debit card|\n|  5|b5b3c8b9-f496-484...|2022-03-07 17:59:47|3bc6c1ea-0198-46d...|   fruit|     standard|      3.99|       4|15.96|        cash|\n|  6|4997b1ae-f5aa-4b9...|2022-03-07 19:36:57|14736243-d346-438...|   fruit|     standard|      1.49|       4| 5.96|    e-wallet|\n|  7|bfffee68-0736-42a...|2022-03-07 19:03:20|0ddc2379-adba-4fb...|   fruit|        basic|      3.99|       4|15.96| credit card|\n|  8|ce50e984-90cd-4b4...|2022-03-07 11:34:32|ad81b46c-bf38-41c...|   fruit|   non-member|      3.99|       1| 3.99| credit card|\n|  9|f0700cc9-e6f5-4b9...|2022-03-07 09:20:12|35e00193-aa27-412...|   fruit|      premium|      0.49|       3| 1.47|    e-wallet|\n| 10|3c46e735-8cb6-4ec...|2022-03-06 12:44:29|ecac012c-1dec-41d...|   fruit|     standard|      4.99|       1| 4.99|        cash|\n| 11|93c9eeb9-314d-4bd...|2022-03-01 14:58:07|3bc6c1ea-0198-46d...|   fruit|      premium|      3.99|       4|15.96|    e-wallet|\n| 12|13049349-04ed-4df...|2022-03-05 10:58:21|ecac012c-1dec-41d...|   fruit|      premium|      4.99|       3|14.97|    e-wallet|\n| 13|05bd411c-b512-49a...|2022-03-04 14:41:58|35e00193-aa27-412...|   fruit|      premium|      0.49|       4| 1.96|    e-wallet|\n| 14|a016533b-7d7e-44b...|2022-03-01 11:20:24|04da844d-8dba-447...|   fruit|         gold|      0.49|       1| 0.49|        cash|\n| 15|464b8d77-bc32-49d...|2022-03-05 19:15:17|0ddc2379-adba-4fb...|   fruit|      premium|      3.99|       4|15.96|    e-wallet|\n| 16|cdadb465-b263-48a...|2022-03-01 19:24:01|14736243-d346-438...|   fruit|     standard|      1.49|       1| 1.49|  debit card|\n| 17|1b5dcfd7-9e27-4fe...|2022-03-05 09:44:16|3bc6c1ea-0198-46d...|   fruit|     standard|      3.99|       3|11.97|    e-wallet|\n| 18|32f8045e-7f73-4e8...|2022-03-01 13:01:48|35e00193-aa27-412...|   fruit|        basic|      0.49|       4| 1.96|  debit card|\n| 19|e0940aa1-f237-49c...|2022-03-01 12:39:17|0ddc2379-adba-4fb...|   fruit|      premium|      3.99|       2| 7.98|    e-wallet|\n+---+--------------------+-------------------+--------------------+--------+-------------+----------+--------+-----+------------+\nonly showing top 20 rows\n\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns from spark dataframe\n",
        "dfSelect = sparkDf.select(\"transaction_id\",\"timestamp\")\n",
        "\n",
        "# show selected\n",
        "dfSelect.show()\n"
      ],
      "metadata": {
        "id": "u0E5lk3nlsYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import month, year\n",
        "\n",
        "sparkDf = sparkDf.withColumn(\"month\", month(\"timestamp\")).withColumn(\"year\", year(\"timestamp\"))\n",
        "\n",
        "# Show DataFrame with new columns\n",
        "sparkDf.show()\n"
      ],
      "metadata": {
        "id": "uPioU9Eopf8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop column from spark dataframe\n",
        "dfDropCol = sparkDf.drop(\"product_id\",\"idx\")\n",
        "\n",
        "#show dropped column df\n",
        "dfDropCol.show()\n"
      ],
      "metadata": {
        "id": "oKwk98cYqEQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename column in Spark dataframe\n",
        "dfRenameCol = sparkDf.withColumnRenamed(\"idx\",\"index\")\n",
        "\n",
        "#show renamed column dataframe\n",
        "dfRenameCol.show()\n"
      ],
      "metadata": {
        "id": "a_qvRWGpqQv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by lastname then print counts of lastname and show\n",
        "sparkDf.groupBy(\"month\",\"year\").count().show()\n"
      ],
      "metadata": {
        "id": "2TpZIsqTqd43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter spark DataFrame for customers who have the last name Adams\n",
        "sparkDf.filter(sparkDf[\"category\"] == \"fruit\").show()"
      ],
      "metadata": {
        "id": "0hKO-KTyrAGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Where clause spark DataFrame for customers who have the last name Adams\n",
        "sparkDf.where(\"category =='fruit'\").show()"
      ],
      "metadata": {
        "id": "sAZjrOhlrLpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, month, sum\n",
        "\n",
        "# Selecting the required columns and applying aggregations\n",
        "resultDf = sparkDf.select(\n",
        "    year(\"timestamp\").alias(\"year\"),\n",
        "    month(\"timestamp\").alias(\"month\"),\n",
        "    \"category\",\n",
        "    sum(\"total\").alias(\"total_amount\"),\n",
        "    sum(\"quantity\").alias(\"total_quantity\")\n",
        ")\n",
        "\n",
        "# Grouping by the specified columns\n",
        "resultDf = resultDf.groupBy(\"year\", \"month\", \"category\").agg(\n",
        "    sum(\"total_amount\").alias(\"total_amount\"),\n",
        "    sum(\"total_quantity\").alias(\"total_quantity\")\n",
        ")\n",
        "\n",
        "resultDf = resultDf.orderBy(\"year\", \"month\", \"category\")\n",
        "\n",
        "resultDf.show()"
      ],
      "metadata": {
        "id": "Ul7I9Ds2rXQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Convert PySpark DataFrame to Pandas DataFrame\n",
        "resultPandas = resultDf.toPandas()\n",
        "\n",
        "# Plotting total amount and total quantity for each category\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='month', y='total_amount', hue='category', data=resultPandas, ci=None)\n",
        "plt.title('Total Amount by Category and Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Amount')\n",
        "plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='month', y='total_quantity', hue='category', data=resultPandas, ci=None)\n",
        "plt.title('Total Quantity by Category and Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Quantity')\n",
        "plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SDFQzWqutkDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert from spark Dataframe to Glue Dynamic DataFrame\n",
        "# Import Dynamic DataFrame class\n",
        "from awsglue.dynamicframe import DynamicFrame\n",
        "\n",
        "#Convert from Spark Data Frame to Glue Dynamic Frame\n",
        "dyfConvert = DynamicFrame.fromDF(resultDf, glueContext, \"convert\")\n",
        "\n",
        "#Show converted Glue Dynamic Frame\n",
        "dyfConvert.show()"
      ],
      "metadata": {
        "id": "NsAMDi6Rsf4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example: Visualize data with matplotlib\n"
      ],
      "metadata": {
        "editable": true,
        "trusted": true,
        "id": "4ldPcUgFlkB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example: Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n"
      ],
      "metadata": {
        "editable": true,
        "trusted": true,
        "id": "KLoCypn8lkCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write down the data in converted Dynamic Frame to S3 location.\n",
        "glueContext.write_dynamic_frame.from_options(\n",
        "                            frame = dyfConvert,\n",
        "                            connection_type=\"s3\",\n",
        "                            connection_options = {\"path\": \"s3://<YOUR_S3_BUCKET_NAME>/write_down_dyf_to_s3\"},\n",
        "                            format = \"csv\",\n",
        "                            format_options={\n",
        "                                \"separator\": \",\"\n",
        "                                },\n",
        "                            transformation_ctx = \"datasink2\")"
      ],
      "metadata": {
        "trusted": true,
        "editable": true,
        "id": "lewK2aEPlkCA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}